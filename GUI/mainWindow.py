# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'mainWindow.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.
import time
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QFileDialog
import json
from paddleocr import PaddleOCR
from utils import prepare_train_features, prepare_validation_features
from functools import partial
import paddlenlp as ppnlp
import paddle
from paddlenlp.metrics.squad import squad_evaluate, compute_prediction
filename = ""
filename1=""
newpicture=False
context=""
MODEL_NAME = "bert-base-chinese"
model = ppnlp.transformers.BertForQuestionAnswering.from_pretrained(MODEL_NAME)
tokenizer = ppnlp.transformers.BertTokenizer.from_pretrained(MODEL_NAME)
import cv2
class Ui_Dialog(object):
    def setupUi(self, Dialog):
        Dialog.setObjectName("Dialog")
        Dialog.resize(400, 259)
        self.textEdit_2 = QtWidgets.QTextEdit(Dialog)
        self.textEdit_2.setGeometry(QtCore.QRect(190, 60, 201, 31))
        self.textEdit_2.setObjectName("textEdit_2")
        self.label_4 = QtWidgets.QLabel(Dialog)
        self.label_4.setGeometry(QtCore.QRect(190, 40, 71, 16))
        self.label_4.setObjectName("label_4")
        self.label_2 = QtWidgets.QLabel(Dialog)
        self.label_2.setGeometry(QtCore.QRect(190, 110, 61, 16))
        self.label_2.setObjectName("label_2")
        self.textEdit_3 = QtWidgets.QTextEdit(Dialog)
        self.textEdit_3.setGeometry(QtCore.QRect(190, 130, 201, 31))
        self.textEdit_3.setObjectName("textEdit_3")
        self.pushButton = QtWidgets.QPushButton(Dialog)
        self.pushButton.setGeometry(QtCore.QRect(200, 190, 65, 20))
        self.pushButton.setObjectName("pushButton")
        self.pushButton_3 = QtWidgets.QPushButton(Dialog)
        self.pushButton_3.setGeometry(QtCore.QRect(10, 10, 65, 20))
        self.pushButton_3.setObjectName("pushButton_3")
        self.label = QtWidgets.QLabel(Dialog)
        self.label.setGeometry(QtCore.QRect(20, 50, 151, 181))
        self.label.setText("")
        self.label.setObjectName("label")
        self.pushButton_4 = QtWidgets.QPushButton(Dialog)
        self.pushButton_4.setGeometry(QtCore.QRect(290, 190, 65, 20))
        self.pushButton_4.setObjectName("pushButton_4")
        self.pushButton_5=QtWidgets.QPushButton(Dialog)
        self.pushButton_5.setGeometry(QtCore.QRect(80, 10, 65, 20))
        self.pushButton_5.setObjectName("pushButton_5")
        self.label_3 = QtWidgets.QLabel(Dialog)
        self.label_3.setGeometry(QtCore.QRect(190, 10, 161, 16))
        self.label_3.setObjectName("label_3")
        self.retranslateUi(Dialog)
        self.pushButton_3.clicked.connect(self.openimage)
        self.pushButton_4.clicked.connect(self.loadmodel)
        self.pushButton.clicked.connect(self.answer)
        self.pushButton_5.clicked.connect(self.takepicture)
        QtCore.QMetaObject.connectSlotsByName(Dialog)
    def answer(self):
        global filename1
        global context
        global newpicture
        if filename1 != filename :   #如果filename发生了改变需要重新进行ocr识别
            ocr = PaddleOCR(use_angle_cls=True,use_gpu=False, lang="ch")
            result = ocr.ocr(filename, cls=True)  # 这里填写文件路径
            lines = [line[1][0] for line in result]
            context = "".join(lines)
            filename1=filename
        elif newpicture==True:
            newpicture = False
            ocr = PaddleOCR(use_angle_cls=True, use_gpu=False, lang="ch")
            result = ocr.ocr("test.png", cls=True)  # 这里填写文件路径
            lines = [line[1][0] for line in result]
            context = "".join(lines)
        question=self.textEdit_2.toPlainText()
        nlp_datas = []
        qas = []
        qa = {
            "question": question,
            "id": "000001",
            "answers": [
                {
                    "text": "无",
                    "answer_start": 0
                }
            ]
        }
        qas.append(qa)
        data = {
            'paragraphs': [
                {
                    "context": context,
                    "title": filename,
                    "qas": qas
                }
            ]
        }
        nlp_datas.append(data)
        dataset = {
            'data': nlp_datas
        }
        with open('test.json', 'w', encoding='utf8') as f:
            json.dump(dataset, f, ensure_ascii=False)
        max_seq_length = 512
        # 文本滑动窗口步幅
        doc_stride = 128
        batch_size = 8
        test_ds = ppnlp.datasets.load_dataset('dureader_robust', data_files='test.json')
        global model
        global tokenizer
        test_trans_func = partial(prepare_validation_features,
                                  max_seq_length=max_seq_length,
                                  doc_stride=doc_stride,
                                  tokenizer=tokenizer)

        test_ds.map(test_trans_func, batched=True)

        from paddlenlp.data import Stack, Dict, Pad
        test_batch_sampler = paddle.io.BatchSampler(
            test_ds, batch_size=batch_size, shuffle=False)

        test_batchify_fn = lambda samples, fn=Dict({
            "input_ids": Pad(axis=0, pad_val=tokenizer.pad_token_id),
            "token_type_ids": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)
        }): fn(samples)

        test_data_loader = paddle.io.DataLoader(
            dataset=test_ds,
            batch_sampler=test_batch_sampler,
            collate_fn=test_batchify_fn,
            return_list=True)
        model.eval()

        all_start_logits = []
        all_end_logits = []
        tic_eval = time.time()

        for batch in test_data_loader:
            input_ids, token_type_ids = batch
            start_logits_tensor, end_logits_tensor = model(input_ids,
                                                           token_type_ids)

            for idx in range(start_logits_tensor.shape[0]):
                if len(all_start_logits) % 1000 == 0 and len(all_start_logits):
                    print("Processing example: %d" % len(all_start_logits))
                    print('time per 1000:', time.time() - tic_eval)
                    tic_eval = time.time()

                all_start_logits.append(start_logits_tensor.numpy()[idx])
                all_end_logits.append(end_logits_tensor.numpy()[idx])

        all_predictions, _, _ = compute_prediction(
            test_data_loader.dataset.data, test_data_loader.dataset.new_data,
            (all_start_logits, all_end_logits), False, 20, 30)

        # Can also write all_nbest_json and scores_diff_json files if needed
        with open('prediction.json', "w", encoding='utf-8') as writer:
            writer.write(
                json.dumps(
                    all_predictions, ensure_ascii=False, indent=4) + "\n")

        squad_evaluate(
            examples=test_data_loader.dataset.data,
            preds=all_predictions,
            is_whitespace_splited=False)

        count = 0
        for example in test_data_loader.dataset.data:
            count += 1
            print()
            print('问题：', example['question'])
            print('原文：', ''.join(example['context']))
            print('答案：', all_predictions[example['id']])
            self.textEdit_3.setText(all_predictions[example['id']])
            if count >= 5:
                break
        model.train()

    def loadmodel(self):
        global model
        global tokenizer
        model = ppnlp.transformers.BertForQuestionAnswering.from_pretrained(
            'C:\\Users\\glh98\\Desktop\\保险问答\\env\\home\\aistudio\\checkpoint')
        tokenizer = ppnlp.transformers.BertTokenizer.from_pretrained(
            'C:\\Users\\glh98\\Desktop\\保险问答\\env\\home\\aistudio\\checkpoint')
        self.label_3.setText("模型加载完成！")
    def takepicture(self):
        global newpicture
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        newpicture=True
        cv2.imwrite("test.png", frame)
        cap.release()
        png = QtGui.QPixmap('test.png').scaled(self.label.width(), self.label.height())
        self.label.setPixmap(png)
    def openimage(self):
        # 打开文件路径
        # 设置文件扩展名过滤,注意用双分号间隔
        global filename
        try:
            imgName, imgType = QFileDialog.getOpenFileName(self,
                                                           "打开图片",
                                                           "",
                                                           " *.jpg;;*.png;;*.jpeg;;*.bmp;;All Files (*)")
            filename=imgName
            #print(imgName)
            # 利用qlabel显示图片
            png = QtGui.QPixmap(imgName).scaled(self.label.width(), self.label.height())
            self.label.setPixmap(png)
        except:
            self.label.setText("文件打开失败！")

    def retranslateUi(self, Dialog):
        _translate = QtCore.QCoreApplication.translate
        Dialog.setWindowTitle(_translate("Dialog", "Dialog"))
        self.label_4.setText(_translate("Dialog", "请输入问题："))
        self.label_2.setText(_translate("Dialog", "回答："))
        self.pushButton.setText(_translate("Dialog", "识别"))
        self.pushButton_3.setText(_translate("Dialog", "加载图片"))
        self.pushButton_4.setText(_translate("Dialog", "加载模型"))
        self.pushButton_5.setText(_translate("Dialog","拍摄照片"))
        self.label_3.setText(_translate("Dialog", "模型未加载！"))
